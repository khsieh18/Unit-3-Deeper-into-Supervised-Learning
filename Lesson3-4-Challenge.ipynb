{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have two new regression methods at your fingertips, it's time to give them a spin. In fact, for this challenge, let's put them together! Pick a dataset of your choice with a binary outcome and the potential for at least 15 features. If you're drawing a blank, the crime rates in 2013 dataset has a lot of variables that could be made into a modelable binary outcome.\n",
    "\n",
    "Engineer your features, then create three models. Each model will be run on a training set and a test-set (or multiple test-sets, if you take a folds approach). The models should be:\n",
    "\n",
    "Vanilla logistic regression\n",
    "Ridge logistic regression\n",
    "Lasso logistic regression\n",
    "If you're stuck on how to begin combining your two new modeling skills, here's a hint: the SKlearn LogisticRegression method has a \"penalty\" argument that takes either 'l1' or 'l2' as a value.\n",
    "\n",
    "In your report, evaluate all three models and decide on your best. Be clear about the decisions you made that led to these models (feature selection, regularization parameter selection, model evaluation criteria) and why you think that particular model is the best of the three. Also reflect on the strengths and limitations of regression as a modeling approach. Were there things you couldn't do but you wish you could have done?\n",
    "\n",
    "Record your work and reflections in a notebook to discuss with your mentor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlrd\n",
    "df=pd.read_csv('binary1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "admit      int64\n",
       "gre        int64\n",
       "gpa      float64\n",
       "rank       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit  gre   gpa  rank\n",
       "0      0  380  3.61     3\n",
       "1      1  660  3.67     3\n",
       "2      1  800  4.00     1\n",
       "3      1  640  3.19     4\n",
       "4      0  520  2.93     4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# features\n",
    "x=df[['gre','gpa']]\n",
    "\n",
    "#labels\n",
    "y=df['admit']\n",
    "\n",
    "#split dataset into training and test set\n",
    "#70% training set and 30% test set\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "#create a vallina logistic regression\n",
    "lr=LogisticRegression(C=1.0)\n",
    "\n",
    "#train the model using training set\n",
    "lr.fit(x_train,y_train)\n",
    "\n",
    "#predict the model using test set\n",
    "y_pred=lr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.665\n"
     ]
    }
   ],
   "source": [
    "#model accuracy, how often is the classifier correct?\n",
    "print(\"accuracy: {}\".format(lr.score(x_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# features\n",
    "x=df[['gre','gpa']]\n",
    "\n",
    "#labels\n",
    "y=df['admit']\n",
    "\n",
    "#split dataset into training and test set\n",
    "#70% training set and 30% test set\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a ridge logistic regression\n",
    "ridge=linear_model.Ridge(alpha=10,fit_intercept=False)\n",
    "\n",
    "#train the model using training set\n",
    "ridge.fit(x_train,y_train)\n",
    "\n",
    "#predict the model using test set\n",
    "y_pred=ridge.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.0001254691813378228\n"
     ]
    }
   ],
   "source": [
    "#model accuracy, how often is the classifier correct?\n",
    "print(\"accuracy: {}\".format(ridge.score(x_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# features\n",
    "x = df[['gpa', 'gre']]\n",
    "\n",
    "#labels\n",
    "y=df['admit']\n",
    "\n",
    "#split dataset into training and test set\n",
    "#70% training set and 30% test set\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a lasso logistic regression\n",
    "lass=linear_model.Lasso(alpha=0.3)\n",
    "\n",
    "#train the model using training set\n",
    "lass.fit(x_train,y_train)\n",
    "\n",
    "#predict the model using test set\n",
    "y_pred=lass.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.03496729083741035\n",
      "accuracy: 0.013775117912969814\n"
     ]
    }
   ],
   "source": [
    "#model accuracy, how often is the classifier correct?\n",
    "print(\"accuracy: {}\".format(lass.score(x_train,y_train)))\n",
    "print(\"accuracy: {}\".format(lass.score(x_test,y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
